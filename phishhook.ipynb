{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVa8R4nWyAy_"
      },
      "source": [
        "# PhishHook - A Phishing URL Detector\n",
        "#### By: Aryaan Khan and Bradley Lewis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9iZYwNqUydlU"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "05wY1ux9x9D7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from urllib.parse import urlparse, parse_qs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Extract URL Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_url_features(url):\n",
        "    features = {}\n",
        "    parsed_url = urlparse(url)\n",
        "    query_params = parse_qs(parsed_url.query)\n",
        "\n",
        "    # Basic features from URL components\n",
        "    features['length_url'] = len(url)\n",
        "    features['length_hostname'] = len(parsed_url.netloc)\n",
        "    features['ip'] = 1 if parsed_url.hostname and parsed_url.hostname.replace('.', '').isdigit() else 0\n",
        "    features['nb_dots'] = url.count('.')\n",
        "    features['nb_hyphens'] = url.count('-')\n",
        "    features['nb_at'] = url.count('@')\n",
        "    features['nb_qm'] = url.count('?')\n",
        "    features['nb_and'] = url.count('&')\n",
        "    features['nb_or'] = url.count('|')\n",
        "    features['nb_eq'] = len(query_params)\n",
        "    features['nb_underscore'] = url.count('_')\n",
        "    features['nb_tilde'] = url.count('~')\n",
        "    features['nb_percent'] = url.count('%')\n",
        "    features['nb_slash'] = url.count('/')\n",
        "    features['nb_star'] = url.count('*')\n",
        "    features['nb_colon'] = url.count(':')\n",
        "    features['nb_comma'] = url.count(',')\n",
        "    features['nb_semicolumn'] = url.count(';')\n",
        "    features['nb_dollar'] = url.count('$')\n",
        "    features['nb_space'] = url.count(' ')\n",
        "    features['nb_dslash'] = url.count('//')\n",
        "\n",
        "    return features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-NbEyT20IkA"
      },
      "source": [
        "## Load the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "dataset = pd.read_csv(\"phishing_data.csv\")\n",
        "\n",
        "# Assuming extract_url_features is already defined and properly imported\n",
        "features = [extract_url_features(url) for url in dataset['URL']]\n",
        "features_df = pd.DataFrame(features)\n",
        "\n",
        "# Assuming the label column is named 'Label' and needs conversion from text to binary\n",
        "labels = (dataset['Label'] == 'bad').astype(int)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TR3DtFf12Ize"
      },
      "source": [
        "## Create the Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_J6ug_ZA2LXF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MPS is available!\n",
            "torch.Size([329607, 21]) torch.Size([329607, 1])\n",
            "torch.Size([109869, 21]) torch.Size([109869, 1])\n",
            "torch.Size([109870, 21]) torch.Size([109870, 1])\n"
          ]
        }
      ],
      "source": [
        "# Check if MPS is available\n",
        "if torch.backends.mps.is_available():\n",
        "    print(\"MPS is available!\")\n",
        "    # Set the device to MPS\n",
        "    device = torch.device(\"mps\")\n",
        "else:\n",
        "    print(\"MPS not available, using CPU\")\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "# Initially split the data into temporary training data and final test data\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(features_df, labels, test_size=0.2)\n",
        "\n",
        "# Split the temporary training data into final training data and validation data\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25)  # 0.25 x 0.8 = 0.2\n",
        "\n",
        "# Convert data to tensors and transfer to the specified device\n",
        "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32).to(device)\n",
        "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1).to(device)\n",
        "X_val_tensor = torch.tensor(X_val.values, dtype=torch.float32).to(device)\n",
        "y_val_tensor = torch.tensor(y_val.values, dtype=torch.float32).view(-1, 1).to(device)\n",
        "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32).to(device)\n",
        "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).view(-1, 1).to(device)\n",
        "\n",
        "# Create Tensor datasets for all sets\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "\n",
        "# Create DataLoaders for all datasets\n",
        "train_loader = DataLoader(train_dataset, batch_size=30000, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=10000, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=10000, shuffle=False)\n",
        "\n",
        "# Confirm the DataLoader details\n",
        "print(train_loader.dataset.tensors[0].shape, train_loader.dataset.tensors[1].shape)\n",
        "print(val_loader.dataset.tensors[0].shape, val_loader.dataset.tensors[1].shape)\n",
        "print(test_loader.dataset.tensors[0].shape, test_loader.dataset.tensors[1].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wo8eJ1Vbyff1"
      },
      "source": [
        "## Define the Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "j-XPOZBIyfIb"
      },
      "outputs": [],
      "source": [
        "class PhishHookNet(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(PhishHookNet, self).__init__()\n",
        "        self.layer1 = nn.Linear(input_size, 128)\n",
        "        self.layer2 = nn.Linear(128, 256)\n",
        "        self.layer3 = nn.Linear(256, 64)\n",
        "        self.output = nn.Linear(64, 1)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.layer1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = torch.relu(self.layer2(x))\n",
        "        x = self.dropout(x)\n",
        "        x = torch.relu(self.layer3(x))\n",
        "        x = torch.sigmoid(self.output(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBNkBiOgyqpW"
      },
      "source": [
        "## Define the Training and Validation Loops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "3MsmK3vP2ggw"
      },
      "outputs": [],
      "source": [
        "# Function to train the model\n",
        "def train(model, train_loader, optimizer, criterion):\n",
        "    model.train()  # Set the model to training mode\n",
        "    total_loss = 0\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()  # Clear gradients\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * inputs.size(0)\n",
        "    return total_loss / len(train_loader.dataset)\n",
        "\n",
        "# Function to validate the model\n",
        "def validate(model, val_loader, criterion):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    total_loss = 0\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():  # No need to track gradients\n",
        "        for inputs, labels in val_loader:\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += loss.item() * inputs.size(0)\n",
        "            predicted = outputs.round()\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    avg_loss = total_loss / len(val_loader.dataset)\n",
        "    accuracy = correct / total * 100\n",
        "    return avg_loss, accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define the Early Stopping Condition Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, patience=5, verbose=False, delta=0):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): How long to wait after last time validation loss improved.\n",
        "                            Default: 7\n",
        "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
        "                            Default: False\n",
        "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
        "                            Default: 0\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.delta = delta\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = float('inf')\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            if self.verbose:\n",
        "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        '''Saves model when validation loss decrease.'''\n",
        "        if self.verbose:\n",
        "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), 'phishing_url_model.pth')\n",
        "        self.val_loss_min = val_loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgfYAE0822ML"
      },
      "source": [
        "## Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Bkekk9wt21hg"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss decreased (inf --> 0.672610).  Saving model ...\n",
            "Epoch 1: train_loss = 1.0449, val_loss = 0.6726\n",
            "Validation loss decreased (0.672610 --> 0.631430).  Saving model ...\n",
            "Epoch 2: train_loss = 0.6617, val_loss = 0.6314\n",
            "Validation loss decreased (0.631430 --> 0.548653).  Saving model ...\n",
            "Epoch 3: train_loss = 0.5915, val_loss = 0.5487\n",
            "Validation loss decreased (0.548653 --> 0.513974).  Saving model ...\n",
            "Epoch 4: train_loss = 0.5387, val_loss = 0.5140\n",
            "Validation loss decreased (0.513974 --> 0.499698).  Saving model ...\n",
            "Epoch 5: train_loss = 0.5127, val_loss = 0.4997\n",
            "Validation loss decreased (0.499698 --> 0.487050).  Saving model ...\n",
            "Epoch 6: train_loss = 0.4992, val_loss = 0.4870\n",
            "Validation loss decreased (0.487050 --> 0.475671).  Saving model ...\n",
            "Epoch 7: train_loss = 0.4880, val_loss = 0.4757\n",
            "Validation loss decreased (0.475671 --> 0.470374).  Saving model ...\n",
            "Epoch 8: train_loss = 0.4801, val_loss = 0.4704\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch 9: train_loss = 0.4801, val_loss = 0.4695\n",
            "Validation loss decreased (0.470374 --> 0.459603).  Saving model ...\n",
            "Epoch 10: train_loss = 0.4746, val_loss = 0.4596\n",
            "Validation loss decreased (0.459603 --> 0.454477).  Saving model ...\n",
            "Epoch 11: train_loss = 0.4674, val_loss = 0.4545\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch 12: train_loss = 0.4653, val_loss = 0.4566\n",
            "EarlyStopping counter: 2 out of 5\n",
            "Epoch 13: train_loss = 0.4674, val_loss = 0.4606\n",
            "Validation loss decreased (0.454477 --> 0.452836).  Saving model ...\n",
            "Epoch 14: train_loss = 0.4632, val_loss = 0.4528\n",
            "Validation loss decreased (0.452836 --> 0.446134).  Saving model ...\n",
            "Epoch 15: train_loss = 0.4595, val_loss = 0.4461\n",
            "Validation loss decreased (0.446134 --> 0.443970).  Saving model ...\n",
            "Epoch 16: train_loss = 0.4553, val_loss = 0.4440\n",
            "Validation loss decreased (0.443970 --> 0.442542).  Saving model ...\n",
            "Epoch 17: train_loss = 0.4535, val_loss = 0.4425\n",
            "Validation loss decreased (0.442542 --> 0.440718).  Saving model ...\n",
            "Epoch 18: train_loss = 0.4520, val_loss = 0.4407\n",
            "Validation loss decreased (0.440718 --> 0.438030).  Saving model ...\n",
            "Epoch 19: train_loss = 0.4494, val_loss = 0.4380\n",
            "Validation loss decreased (0.438030 --> 0.436309).  Saving model ...\n",
            "Epoch 20: train_loss = 0.4500, val_loss = 0.4363\n",
            "Validation loss decreased (0.436309 --> 0.434804).  Saving model ...\n",
            "Epoch 21: train_loss = 0.4465, val_loss = 0.4348\n",
            "Validation loss decreased (0.434804 --> 0.431069).  Saving model ...\n",
            "Epoch 22: train_loss = 0.4460, val_loss = 0.4311\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch 23: train_loss = 0.4418, val_loss = 0.4301\n",
            "EarlyStopping counter: 2 out of 5\n",
            "Epoch 24: train_loss = 0.4410, val_loss = 0.4321\n",
            "EarlyStopping counter: 3 out of 5\n",
            "Epoch 25: train_loss = 0.4395, val_loss = 0.4301\n",
            "Validation loss decreased (0.431069 --> 0.426795).  Saving model ...\n",
            "Epoch 26: train_loss = 0.4382, val_loss = 0.4268\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch 27: train_loss = 0.4373, val_loss = 0.4288\n",
            "Validation loss decreased (0.426795 --> 0.424972).  Saving model ...\n",
            "Epoch 28: train_loss = 0.4359, val_loss = 0.4250\n",
            "Validation loss decreased (0.424972 --> 0.423345).  Saving model ...\n",
            "Epoch 29: train_loss = 0.4344, val_loss = 0.4233\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch 30: train_loss = 0.4341, val_loss = 0.4235\n",
            "EarlyStopping counter: 2 out of 5\n",
            "Epoch 31: train_loss = 0.4329, val_loss = 0.4228\n",
            "Validation loss decreased (0.423345 --> 0.421307).  Saving model ...\n",
            "Epoch 32: train_loss = 0.4322, val_loss = 0.4213\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch 33: train_loss = 0.4317, val_loss = 0.4228\n",
            "EarlyStopping counter: 2 out of 5\n",
            "Epoch 34: train_loss = 0.4326, val_loss = 0.4222\n",
            "EarlyStopping counter: 3 out of 5\n",
            "Epoch 35: train_loss = 0.4339, val_loss = 0.4215\n",
            "EarlyStopping counter: 4 out of 5\n",
            "Epoch 36: train_loss = 0.4350, val_loss = 0.4300\n",
            "EarlyStopping counter: 5 out of 5\n",
            "Early stopping\n"
          ]
        }
      ],
      "source": [
        "# Assuming the model and dataset are already defined\n",
        "model = PhishHookNet(input_size=X_train.shape[1]).to(device)  # Adjust input size based on actual features\n",
        "\n",
        "# Loss function, optimizer, and early stopping\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=0.0001)\n",
        "early_stopping = EarlyStopping(verbose=True, delta=0.001)\n",
        "\n",
        "# Training loop with model saving based on validation loss improvement\n",
        "num_epochs = 50\n",
        "best_val_loss = float('inf')\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss = train(model, train_loader, optimizer, criterion)\n",
        "    val_loss, accuracy = validate(model, val_loader, criterion)\n",
        "    \n",
        "    # Early stopping\n",
        "    early_stopping(val_loss, model)\n",
        "    if early_stopping.early_stop:\n",
        "        print(\"Early stopping\")\n",
        "        break\n",
        "\n",
        "    print(f'Epoch {epoch+1}: train_loss = {train_loss:.4f}, val_loss = {val_loss:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training accuracy: 80.08%\n",
            "Validation accuracy: 80.40%\n",
            "Test accuracy: 80.15%\n"
          ]
        }
      ],
      "source": [
        "# Load the best model back\n",
        "model.load_state_dict(torch.load('phishing_url_model.pth'))\n",
        "\n",
        "# Evaluate the model on the test dataset\n",
        "model.eval()\n",
        "\n",
        "# Calculate accuracy\n",
        "train_accuracy = validate(model, train_loader, criterion)[1]\n",
        "val_accuracy = validate(model, val_loader, criterion)[1]\n",
        "test_accuracy = validate(model, test_loader, criterion)[1]\n",
        "\n",
        "# Print the results\n",
        "print(f'Training accuracy: {train_accuracy:.2f}%')\n",
        "print(f'Validation accuracy: {val_accuracy:.2f}%')\n",
        "print(f'Test accuracy: {test_accuracy:.2f}%')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
