{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVa8R4nWyAy_"
      },
      "source": [
        "# PhishHook - A Phishing URL Detector - UCI Dataset\n",
        "#### By: Aryaan Khan and Bradley Lewis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9iZYwNqUydlU"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "05wY1ux9x9D7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from phishhooknet import PhishHookNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-NbEyT20IkA"
      },
      "source": [
        "## Load the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ucimlrepo import fetch_ucirepo \n",
        "  \n",
        "# Fetch the phishing website dataset from the UCI ML Repository\n",
        "phiusiil_phishing_url_website = fetch_ucirepo(id=967) \n",
        "X = phiusiil_phishing_url_website.data.features \n",
        "y = phiusiil_phishing_url_website.data.targets\n",
        "\n",
        "# Define which features to use\n",
        "feature_names = [\n",
        "    'URLLength', 'DomainLength', 'IsDomainIP',\n",
        "    'TLDLength', 'NoOfSubDomain', 'HasObfuscation', 'IsHTTPS', 'NoOfEqualsInURL',\n",
        "    'NoOfQMarkInURL', 'NoOfAmpersandInURL', 'NoOfOtherSpecialCharsInURL',\n",
        "    'SpacialCharRatioInURL', 'NoOfLettersInURL', 'LetterRatioInURL',\n",
        "    'NoOfDegitsInURL', 'DegitRatioInURL'\n",
        "]\n",
        "X = X[feature_names]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TR3DtFf12Ize"
      },
      "source": [
        "## Create the Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_J6ug_ZA2LXF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MPS is available!\n",
            "torch.Size([141477, 16]) torch.Size([141477, 1])\n",
            "torch.Size([47159, 16]) torch.Size([47159, 1])\n",
            "torch.Size([47159, 16]) torch.Size([47159, 1])\n"
          ]
        }
      ],
      "source": [
        "# Select the device to use\n",
        "if torch.backends.mps.is_available():\n",
        "    print(\"MPS is available!\")\n",
        "    device = torch.device(\"mps\")\n",
        "elif torch.cuda.is_available():\n",
        "    print(\"CUDA is available!\")\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    print(\"CUDA not available. Using CPU instead.\")\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "# Split the data into temporary training data and final test data\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Split the temporary training data into final training data and validation data\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42)  # 0.25 x 0.8 = 0.2\n",
        "\n",
        "# Convert the columns to numeric values\n",
        "X_train = X_train.apply(pd.to_numeric, errors='coerce')\n",
        "X_val = X_val.apply(pd.to_numeric, errors='coerce')\n",
        "X_test = X_test.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# Handle missing values if there are any\n",
        "X_train = X_train.fillna(0)\n",
        "X_val = X_val.fillna(0)\n",
        "X_test = X_test.fillna(0)\n",
        "\n",
        "# Convert data to tensors and transfer to the specified device\n",
        "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32).to(device)\n",
        "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1).to(device)\n",
        "X_val_tensor = torch.tensor(X_val.values, dtype=torch.float32).to(device)\n",
        "y_val_tensor = torch.tensor(y_val.values, dtype=torch.float32).view(-1, 1).to(device)\n",
        "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32).to(device)\n",
        "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).view(-1, 1).to(device)\n",
        "\n",
        "# Create Tensor datasets for all sets\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "\n",
        "# Create DataLoaders for all datasets\n",
        "train_loader = DataLoader(train_dataset, batch_size=10000, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=3000, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=3000, shuffle=False)\n",
        "\n",
        "# Confirm the DataLoader shapes\n",
        "print(train_loader.dataset.tensors[0].shape, train_loader.dataset.tensors[1].shape)\n",
        "print(val_loader.dataset.tensors[0].shape, val_loader.dataset.tensors[1].shape)\n",
        "print(test_loader.dataset.tensors[0].shape, test_loader.dataset.tensors[1].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBNkBiOgyqpW"
      },
      "source": [
        "## Define the Training and Validation Loops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "3MsmK3vP2ggw"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, optimizer, criterion):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * inputs.size(0)\n",
        "    return total_loss / len(train_loader.dataset)\n",
        "\n",
        "def validate(model, val_loader, criterion):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += loss.item() * inputs.size(0)\n",
        "            predicted = outputs.round()\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    avg_loss = total_loss / len(val_loader.dataset)\n",
        "    accuracy = correct / total * 100\n",
        "    return avg_loss, accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define the Early Stopping Condition Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, patience=5, verbose=False, delta=0):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): How long to wait after last time validation loss improved.\n",
        "                            Default: 7\n",
        "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
        "                            Default: False\n",
        "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
        "                            Default: 0\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.delta = delta\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = float('inf')\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            if self.verbose:\n",
        "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        '''\n",
        "        Saves model when validation loss decrease.\n",
        "        '''\n",
        "        if self.verbose:\n",
        "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), 'phishing_uci_url_model.pth')\n",
        "        self.val_loss_min = val_loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgfYAE0822ML"
      },
      "source": [
        "## Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize the model\n",
        "model = PhishHookNet(input_size=X_train.shape[1]).to(device)\n",
        "\n",
        "# Loss function, optimizer, and early stopping\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=0.0001)\n",
        "early_stopping = EarlyStopping(patience=5, verbose=True, delta=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Bkekk9wt21hg"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss decreased (inf --> 0.351049).  Saving model ...\n",
            "Epoch 1: train_loss = 0.8733, val_loss = 0.3510\n",
            "Validation loss decreased (0.351049 --> 0.287188).  Saving model ...\n",
            "Epoch 2: train_loss = 0.3719, val_loss = 0.2872\n",
            "Validation loss decreased (0.287188 --> 0.082909).  Saving model ...\n",
            "Epoch 3: train_loss = 0.2160, val_loss = 0.0829\n",
            "Validation loss decreased (0.082909 --> 0.023130).  Saving model ...\n",
            "Epoch 4: train_loss = 0.0574, val_loss = 0.0231\n",
            "Validation loss decreased (0.023130 --> 0.019216).  Saving model ...\n",
            "Epoch 5: train_loss = 0.0255, val_loss = 0.0192\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch 6: train_loss = 0.0202, val_loss = 0.0207\n",
            "EarlyStopping counter: 2 out of 5\n",
            "Epoch 7: train_loss = 0.0190, val_loss = 0.0197\n",
            "Validation loss decreased (0.019216 --> 0.016870).  Saving model ...\n",
            "Epoch 8: train_loss = 0.0184, val_loss = 0.0169\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch 9: train_loss = 0.0171, val_loss = 0.0176\n",
            "EarlyStopping counter: 2 out of 5\n",
            "Epoch 10: train_loss = 0.0168, val_loss = 0.0168\n",
            "EarlyStopping counter: 3 out of 5\n",
            "Epoch 11: train_loss = 0.0165, val_loss = 0.0197\n",
            "Validation loss decreased (0.016870 --> 0.015434).  Saving model ...\n",
            "Epoch 12: train_loss = 0.0169, val_loss = 0.0154\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch 13: train_loss = 0.0157, val_loss = 0.0166\n",
            "EarlyStopping counter: 2 out of 5\n",
            "Epoch 14: train_loss = 0.0154, val_loss = 0.0189\n",
            "EarlyStopping counter: 3 out of 5\n",
            "Epoch 15: train_loss = 0.3591, val_loss = 0.2804\n",
            "EarlyStopping counter: 4 out of 5\n",
            "Epoch 16: train_loss = 0.2280, val_loss = 0.0743\n",
            "EarlyStopping counter: 5 out of 5\n",
            "Early stopping\n"
          ]
        }
      ],
      "source": [
        "# Training loop with model saving based on validation loss improvement\n",
        "num_epochs = 50\n",
        "best_val_loss = float('inf')\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss = train(model, train_loader, optimizer, criterion)\n",
        "    val_loss, accuracy = validate(model, val_loader, criterion)\n",
        "    \n",
        "    # Early stopping\n",
        "    early_stopping(val_loss, model)\n",
        "    if early_stopping.early_stop:\n",
        "        print(\"Early stopping\")\n",
        "        break\n",
        "\n",
        "    print(f'Epoch {epoch+1}: train_loss = {train_loss:.4f}, val_loss = {val_loss:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training accuracy: 99.74%\n",
            "Validation accuracy: 99.69%\n",
            "Test accuracy: 99.74%\n"
          ]
        }
      ],
      "source": [
        "# Load the best model back\n",
        "model = PhishHookNet(input_size=X_train.shape[1]).to(device)\n",
        "model.load_state_dict(torch.load('phishing_uci_url_model.pth'))\n",
        "\n",
        "# Evaluate the model on the test dataset\n",
        "model.eval()\n",
        "\n",
        "# Calculate accuracy\n",
        "train_accuracy = validate(model, train_loader, criterion)[1]\n",
        "val_accuracy = validate(model, val_loader, criterion)[1]\n",
        "test_accuracy = validate(model, test_loader, criterion)[1]\n",
        "\n",
        "# Print the results\n",
        "print(f'Training accuracy: {train_accuracy:.2f}%')\n",
        "print(f'Validation accuracy: {val_accuracy:.2f}%')\n",
        "print(f'Test accuracy: {test_accuracy:.2f}%')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
