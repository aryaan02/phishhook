{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVa8R4nWyAy_"
      },
      "source": [
        "# PhishHook - A Phishing URL Detector - UCI Dataset\n",
        "#### By: Aryaan Khan and Bradley Lewis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9iZYwNqUydlU"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "05wY1ux9x9D7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from phishhooknet import PhishHookNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-NbEyT20IkA"
      },
      "source": [
        "## Load the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ucimlrepo import fetch_ucirepo \n",
        "  \n",
        "# fetch dataset \n",
        "phiusiil_phishing_url_website = fetch_ucirepo(id=967) \n",
        "  \n",
        "# data (as pandas dataframes) \n",
        "X = phiusiil_phishing_url_website.data.features \n",
        "y = phiusiil_phishing_url_website.data.targets\n",
        "\n",
        "feature_names = [\n",
        "    'URLLength', 'DomainLength', 'IsDomainIP',\n",
        "    'TLDLength', 'NoOfSubDomain', 'HasObfuscation', 'IsHTTPS', 'NoOfEqualsInURL',\n",
        "    'NoOfQMarkInURL', 'NoOfAmpersandInURL', 'NoOfOtherSpecialCharsInURL',\n",
        "    'SpacialCharRatioInURL', 'NoOfLettersInURL', 'LetterRatioInURL',\n",
        "    'NoOfDegitsInURL', 'DegitRatioInURL'\n",
        "]\n",
        "\n",
        "# Select only the columns that are included in the feature_names list\n",
        "X = X[feature_names]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TR3DtFf12Ize"
      },
      "source": [
        "## Create the Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_J6ug_ZA2LXF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MPS is available!\n",
            "torch.Size([141477, 16]) torch.Size([141477, 1])\n",
            "torch.Size([47159, 16]) torch.Size([47159, 1])\n",
            "torch.Size([47159, 16]) torch.Size([47159, 1])\n"
          ]
        }
      ],
      "source": [
        "# Check if MPS is available\n",
        "if torch.backends.mps.is_available():\n",
        "    print(\"MPS is available!\")\n",
        "    # Set the device to MPS\n",
        "    device = torch.device(\"mps\")\n",
        "elif torch.cuda.is_available():\n",
        "    print(\"CUDA is available!\")\n",
        "    # Set the device to CUDA\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    print(\"CUDA not available. Using CPU instead.\")\n",
        "    # Set the device to CPU\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "# Split the data into temporary training data and final test data\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Split the temporary training data into final training data and validation data\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42)  # 0.25 x 0.8 = 0.2\n",
        "\n",
        "# Convert all columns to float (adjust based on your specific data needs)\n",
        "X_train = X_train.apply(pd.to_numeric, errors='coerce')\n",
        "X_val = X_val.apply(pd.to_numeric, errors='coerce')\n",
        "X_test = X_test.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# Handle missing values if there are any\n",
        "X_train = X_train.fillna(0)\n",
        "X_val = X_val.fillna(0)\n",
        "X_test = X_test.fillna(0)\n",
        "\n",
        "# Convert data to tensors and transfer to the specified device\n",
        "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32).to(device)\n",
        "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1).to(device)\n",
        "X_val_tensor = torch.tensor(X_val.values, dtype=torch.float32).to(device)\n",
        "y_val_tensor = torch.tensor(y_val.values, dtype=torch.float32).view(-1, 1).to(device)\n",
        "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32).to(device)\n",
        "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).view(-1, 1).to(device)\n",
        "\n",
        "# Create Tensor datasets for all sets\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "\n",
        "# Create DataLoaders for all datasets\n",
        "train_loader = DataLoader(train_dataset, batch_size=30000, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=10000, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=10000, shuffle=False)\n",
        "\n",
        "# Confirm the DataLoader details\n",
        "print(train_loader.dataset.tensors[0].shape, train_loader.dataset.tensors[1].shape)\n",
        "print(val_loader.dataset.tensors[0].shape, val_loader.dataset.tensors[1].shape)\n",
        "print(test_loader.dataset.tensors[0].shape, test_loader.dataset.tensors[1].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBNkBiOgyqpW"
      },
      "source": [
        "## Define the Training and Validation Loops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3MsmK3vP2ggw"
      },
      "outputs": [],
      "source": [
        "# Function to train the model\n",
        "def train(model, train_loader, optimizer, criterion):\n",
        "    model.train()  # Set the model to training mode\n",
        "    total_loss = 0\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()  # Clear gradients\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * inputs.size(0)\n",
        "    return total_loss / len(train_loader.dataset)\n",
        "\n",
        "# Function to validate the model\n",
        "def validate(model, val_loader, criterion):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    total_loss = 0\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():  # No need to track gradients\n",
        "        for inputs, labels in val_loader:\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += loss.item() * inputs.size(0)\n",
        "            predicted = outputs.round()\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    avg_loss = total_loss / len(val_loader.dataset)\n",
        "    accuracy = correct / total * 100\n",
        "    return avg_loss, accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define the Early Stopping Condition Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, patience=5, verbose=False, delta=0):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): How long to wait after last time validation loss improved.\n",
        "                            Default: 7\n",
        "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
        "                            Default: False\n",
        "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
        "                            Default: 0\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.delta = delta\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = float('inf')\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            if self.verbose:\n",
        "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        '''Saves model when validation loss decrease.'''\n",
        "        if self.verbose:\n",
        "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        # torch.save(model.state_dict(), 'phishing_uci_url_model.pth')\n",
        "        self.val_loss_min = val_loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgfYAE0822ML"
      },
      "source": [
        "## Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Assuming the model and dataset are already defined\n",
        "model = PhishHookNet(input_size=X_train.shape[1]).to(device)  # Adjust input size based on actual features\n",
        "\n",
        "# Loss function, optimizer, and early stopping\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=0.0001)\n",
        "early_stopping = EarlyStopping(patience=5, verbose=True, delta=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Bkekk9wt21hg"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss decreased (inf --> 0.691985).  Saving model ...\n",
            "Epoch 1: train_loss = 1.5519, val_loss = 0.6920\n",
            "Validation loss decreased (0.691985 --> 0.639180).  Saving model ...\n",
            "Epoch 2: train_loss = 0.6782, val_loss = 0.6392\n",
            "Validation loss decreased (0.639180 --> 0.456165).  Saving model ...\n",
            "Epoch 3: train_loss = 0.5950, val_loss = 0.4562\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch 4: train_loss = 0.4727, val_loss = 0.4775\n",
            "Validation loss decreased (0.456165 --> 0.360088).  Saving model ...\n",
            "Epoch 5: train_loss = 0.4212, val_loss = 0.3601\n",
            "Validation loss decreased (0.360088 --> 0.301528).  Saving model ...\n",
            "Epoch 6: train_loss = 0.3450, val_loss = 0.3015\n",
            "Validation loss decreased (0.301528 --> 0.230024).  Saving model ...\n",
            "Epoch 7: train_loss = 0.2914, val_loss = 0.2300\n",
            "Validation loss decreased (0.230024 --> 0.163641).  Saving model ...\n",
            "Epoch 8: train_loss = 0.2276, val_loss = 0.1636\n",
            "Validation loss decreased (0.163641 --> 0.097220).  Saving model ...\n",
            "Epoch 9: train_loss = 0.1601, val_loss = 0.0972\n",
            "Validation loss decreased (0.097220 --> 0.057629).  Saving model ...\n",
            "Epoch 10: train_loss = 0.1012, val_loss = 0.0576\n",
            "Validation loss decreased (0.057629 --> 0.034522).  Saving model ...\n",
            "Epoch 11: train_loss = 0.0594, val_loss = 0.0345\n",
            "Validation loss decreased (0.034522 --> 0.025898).  Saving model ...\n",
            "Epoch 12: train_loss = 0.0372, val_loss = 0.0259\n",
            "Validation loss decreased (0.025898 --> 0.024104).  Saving model ...\n",
            "Epoch 13: train_loss = 0.0302, val_loss = 0.0241\n",
            "Validation loss decreased (0.024104 --> 0.022117).  Saving model ...\n",
            "Epoch 14: train_loss = 0.0270, val_loss = 0.0221\n",
            "Validation loss decreased (0.022117 --> 0.019683).  Saving model ...\n",
            "Epoch 15: train_loss = 0.0239, val_loss = 0.0197\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch 16: train_loss = 0.0222, val_loss = 0.0188\n",
            "EarlyStopping counter: 2 out of 5\n",
            "Epoch 17: train_loss = 0.0209, val_loss = 0.0192\n",
            "EarlyStopping counter: 3 out of 5\n",
            "Epoch 18: train_loss = 0.0201, val_loss = 0.0191\n",
            "EarlyStopping counter: 4 out of 5\n",
            "Epoch 19: train_loss = 0.0193, val_loss = 0.0188\n",
            "Validation loss decreased (0.019683 --> 0.018655).  Saving model ...\n",
            "Epoch 20: train_loss = 0.0189, val_loss = 0.0187\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch 21: train_loss = 0.0184, val_loss = 0.0178\n",
            "EarlyStopping counter: 2 out of 5\n",
            "Epoch 22: train_loss = 0.0183, val_loss = 0.0189\n",
            "EarlyStopping counter: 3 out of 5\n",
            "Epoch 23: train_loss = 0.0181, val_loss = 0.0182\n",
            "Validation loss decreased (0.018655 --> 0.017452).  Saving model ...\n",
            "Epoch 24: train_loss = 0.0172, val_loss = 0.0175\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch 25: train_loss = 0.0174, val_loss = 0.0178\n",
            "EarlyStopping counter: 2 out of 5\n",
            "Epoch 26: train_loss = 0.0166, val_loss = 0.0169\n",
            "EarlyStopping counter: 3 out of 5\n",
            "Epoch 27: train_loss = 0.0166, val_loss = 0.0167\n",
            "EarlyStopping counter: 4 out of 5\n",
            "Epoch 28: train_loss = 0.0168, val_loss = 0.0171\n",
            "Validation loss decreased (0.017452 --> 0.016228).  Saving model ...\n",
            "Epoch 29: train_loss = 0.0164, val_loss = 0.0162\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch 30: train_loss = 0.0164, val_loss = 0.0160\n",
            "EarlyStopping counter: 2 out of 5\n",
            "Epoch 31: train_loss = 0.0163, val_loss = 0.0164\n",
            "EarlyStopping counter: 3 out of 5\n",
            "Epoch 32: train_loss = 0.0162, val_loss = 0.0169\n",
            "EarlyStopping counter: 4 out of 5\n",
            "Epoch 33: train_loss = 0.0163, val_loss = 0.0161\n",
            "Validation loss decreased (0.016228 --> 0.015152).  Saving model ...\n",
            "Epoch 34: train_loss = 0.0161, val_loss = 0.0152\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch 35: train_loss = 0.0158, val_loss = 0.0150\n",
            "EarlyStopping counter: 2 out of 5\n",
            "Epoch 36: train_loss = 0.0155, val_loss = 0.0149\n",
            "EarlyStopping counter: 3 out of 5\n",
            "Epoch 37: train_loss = 0.0160, val_loss = 0.0150\n",
            "EarlyStopping counter: 4 out of 5\n",
            "Epoch 38: train_loss = 0.0153, val_loss = 0.0152\n",
            "EarlyStopping counter: 5 out of 5\n",
            "Early stopping\n"
          ]
        }
      ],
      "source": [
        "# Training loop with model saving based on validation loss improvement\n",
        "num_epochs = 50\n",
        "best_val_loss = float('inf')\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss = train(model, train_loader, optimizer, criterion)\n",
        "    val_loss, accuracy = validate(model, val_loader, criterion)\n",
        "    \n",
        "    # Early stopping\n",
        "    early_stopping(val_loss, model)\n",
        "    if early_stopping.early_stop:\n",
        "        print(\"Early stopping\")\n",
        "        break\n",
        "\n",
        "    print(f'Epoch {epoch+1}: train_loss = {train_loss:.4f}, val_loss = {val_loss:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training accuracy: 99.74%\n",
            "Validation accuracy: 99.68%\n",
            "Test accuracy: 99.74%\n"
          ]
        }
      ],
      "source": [
        "# Load the best model back\n",
        "model = PhishHookNet(input_size=X_train.shape[1]).to(device)\n",
        "model.load_state_dict(torch.load('phishing_uci_url_model.pth'))\n",
        "\n",
        "# Evaluate the model on the test dataset\n",
        "model.eval()\n",
        "\n",
        "# Calculate accuracy\n",
        "train_accuracy = validate(model, train_loader, criterion)[1]\n",
        "val_accuracy = validate(model, val_loader, criterion)[1]\n",
        "test_accuracy = validate(model, test_loader, criterion)[1]\n",
        "\n",
        "# Print the results\n",
        "print(f'Training accuracy: {train_accuracy:.2f}%')\n",
        "print(f'Validation accuracy: {val_accuracy:.2f}%')\n",
        "print(f'Test accuracy: {test_accuracy:.2f}%')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
