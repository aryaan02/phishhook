{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVa8R4nWyAy_"
      },
      "source": [
        "# PhishHook - A Phishing URL Detector\n",
        "#### By: Aryaan Khan and Bradley Lewis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9iZYwNqUydlU"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "05wY1ux9x9D7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from url_parser import extract_url_features\n",
        "from phishhooknet import PhishHookNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-NbEyT20IkA"
      },
      "source": [
        "## Load the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "dataset = pd.read_csv(\"phishing_data.csv\")\n",
        "\n",
        "# Assuming extract_url_features is already defined and properly imported\n",
        "features = [extract_url_features(url) for url in dataset['URL']]\n",
        "features_df = pd.DataFrame(features)\n",
        "\n",
        "# Assuming the label column is named 'Label' and needs conversion from text to binary\n",
        "labels = (dataset['Label'] == 'bad').astype(int)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TR3DtFf12Ize"
      },
      "source": [
        "## Create the Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_J6ug_ZA2LXF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MPS is available!\n",
            "torch.Size([329607, 21]) torch.Size([329607, 1])\n",
            "torch.Size([109869, 21]) torch.Size([109869, 1])\n",
            "torch.Size([109870, 21]) torch.Size([109870, 1])\n"
          ]
        }
      ],
      "source": [
        "# Check if MPS is available\n",
        "if torch.backends.mps.is_available():\n",
        "    print(\"MPS is available!\")\n",
        "    # Set the device to MPS\n",
        "    device = torch.device(\"mps\")\n",
        "elif torch.cuda.is_available():\n",
        "    print(\"CUDA is available!\")\n",
        "    # Set the device to CUDA\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    print(\"CUDA not available. Using CPU instead.\")\n",
        "    # Set the device to CPU\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "# Initially split the data into temporary training data and final test data\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(features_df, labels, test_size=0.2)\n",
        "\n",
        "# Split the temporary training data into final training data and validation data\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25)  # 0.25 x 0.8 = 0.2\n",
        "\n",
        "# Convert data to tensors and transfer to the specified device\n",
        "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32).to(device)\n",
        "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1).to(device)\n",
        "X_val_tensor = torch.tensor(X_val.values, dtype=torch.float32).to(device)\n",
        "y_val_tensor = torch.tensor(y_val.values, dtype=torch.float32).view(-1, 1).to(device)\n",
        "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32).to(device)\n",
        "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).view(-1, 1).to(device)\n",
        "\n",
        "# Create Tensor datasets for all sets\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "\n",
        "# Create DataLoaders for all datasets\n",
        "train_loader = DataLoader(train_dataset, batch_size=30000, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=10000, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=10000, shuffle=False)\n",
        "\n",
        "# Confirm the DataLoader details\n",
        "print(train_loader.dataset.tensors[0].shape, train_loader.dataset.tensors[1].shape)\n",
        "print(val_loader.dataset.tensors[0].shape, val_loader.dataset.tensors[1].shape)\n",
        "print(test_loader.dataset.tensors[0].shape, test_loader.dataset.tensors[1].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBNkBiOgyqpW"
      },
      "source": [
        "## Define the Training and Validation Loops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "3MsmK3vP2ggw"
      },
      "outputs": [],
      "source": [
        "# Function to train the model\n",
        "def train(model, train_loader, optimizer, criterion):\n",
        "    model.train()  # Set the model to training mode\n",
        "    total_loss = 0\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()  # Clear gradients\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * inputs.size(0)\n",
        "    return total_loss / len(train_loader.dataset)\n",
        "\n",
        "# Function to validate the model\n",
        "def validate(model, val_loader, criterion):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    total_loss = 0\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():  # No need to track gradients\n",
        "        for inputs, labels in val_loader:\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += loss.item() * inputs.size(0)\n",
        "            predicted = outputs.round()\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    avg_loss = total_loss / len(val_loader.dataset)\n",
        "    accuracy = correct / total * 100\n",
        "    return avg_loss, accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define the Early Stopping Condition Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, patience=5, verbose=False, delta=0):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): How long to wait after last time validation loss improved.\n",
        "                            Default: 7\n",
        "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
        "                            Default: False\n",
        "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
        "                            Default: 0\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.delta = delta\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = float('inf')\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            if self.verbose:\n",
        "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        '''Saves model when validation loss decrease.'''\n",
        "        if self.verbose:\n",
        "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), 'phishing_url_model.pth')\n",
        "        self.val_loss_min = val_loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgfYAE0822ML"
      },
      "source": [
        "## Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Bkekk9wt21hg"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss decreased (inf --> 0.672666).  Saving model ...\n",
            "Epoch 1: train_loss = 1.0210, val_loss = 0.6727\n",
            "Validation loss decreased (0.672666 --> 0.641009).  Saving model ...\n",
            "Epoch 2: train_loss = 0.6618, val_loss = 0.6410\n",
            "Validation loss decreased (0.641009 --> 0.556865).  Saving model ...\n",
            "Epoch 3: train_loss = 0.6039, val_loss = 0.5569\n",
            "Validation loss decreased (0.556865 --> 0.515889).  Saving model ...\n",
            "Epoch 4: train_loss = 0.5445, val_loss = 0.5159\n",
            "Validation loss decreased (0.515889 --> 0.504627).  Saving model ...\n",
            "Epoch 5: train_loss = 0.5188, val_loss = 0.5046\n",
            "Validation loss decreased (0.504627 --> 0.488589).  Saving model ...\n",
            "Epoch 6: train_loss = 0.4976, val_loss = 0.4886\n",
            "Validation loss decreased (0.488589 --> 0.480058).  Saving model ...\n",
            "Epoch 7: train_loss = 0.4862, val_loss = 0.4801\n",
            "Validation loss decreased (0.480058 --> 0.473524).  Saving model ...\n",
            "Epoch 8: train_loss = 0.4792, val_loss = 0.4735\n",
            "Validation loss decreased (0.473524 --> 0.466993).  Saving model ...\n",
            "Epoch 9: train_loss = 0.4742, val_loss = 0.4670\n",
            "Validation loss decreased (0.466993 --> 0.462751).  Saving model ...\n",
            "Epoch 10: train_loss = 0.4701, val_loss = 0.4628\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch 11: train_loss = 0.4688, val_loss = 0.4645\n",
            "Validation loss decreased (0.462751 --> 0.458986).  Saving model ...\n",
            "Epoch 12: train_loss = 0.4662, val_loss = 0.4590\n",
            "Validation loss decreased (0.458986 --> 0.451484).  Saving model ...\n",
            "Epoch 13: train_loss = 0.4597, val_loss = 0.4515\n",
            "Validation loss decreased (0.451484 --> 0.448420).  Saving model ...\n",
            "Epoch 14: train_loss = 0.4545, val_loss = 0.4484\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch 15: train_loss = 0.4526, val_loss = 0.4520\n",
            "EarlyStopping counter: 2 out of 5\n",
            "Epoch 16: train_loss = 0.4531, val_loss = 0.4508\n",
            "Validation loss decreased (0.448420 --> 0.444173).  Saving model ...\n",
            "Epoch 17: train_loss = 0.4540, val_loss = 0.4442\n",
            "Validation loss decreased (0.444173 --> 0.442634).  Saving model ...\n",
            "Epoch 18: train_loss = 0.4504, val_loss = 0.4426\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch 19: train_loss = 0.4483, val_loss = 0.4420\n",
            "Validation loss decreased (0.442634 --> 0.437714).  Saving model ...\n",
            "Epoch 20: train_loss = 0.4469, val_loss = 0.4377\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch 21: train_loss = 0.4451, val_loss = 0.4368\n",
            "Validation loss decreased (0.437714 --> 0.436201).  Saving model ...\n",
            "Epoch 22: train_loss = 0.4434, val_loss = 0.4362\n",
            "Validation loss decreased (0.436201 --> 0.434385).  Saving model ...\n",
            "Epoch 23: train_loss = 0.4415, val_loss = 0.4344\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch 24: train_loss = 0.4399, val_loss = 0.4336\n",
            "Validation loss decreased (0.434385 --> 0.429773).  Saving model ...\n",
            "Epoch 25: train_loss = 0.4377, val_loss = 0.4298\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch 26: train_loss = 0.4370, val_loss = 0.4304\n",
            "Validation loss decreased (0.429773 --> 0.427180).  Saving model ...\n",
            "Epoch 27: train_loss = 0.4350, val_loss = 0.4272\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch 28: train_loss = 0.4350, val_loss = 0.4326\n",
            "EarlyStopping counter: 2 out of 5\n",
            "Epoch 29: train_loss = 0.4370, val_loss = 0.4264\n",
            "EarlyStopping counter: 3 out of 5\n",
            "Epoch 30: train_loss = 0.4337, val_loss = 0.4266\n",
            "EarlyStopping counter: 4 out of 5\n",
            "Epoch 31: train_loss = 0.4336, val_loss = 0.4311\n",
            "Validation loss decreased (0.427180 --> 0.425334).  Saving model ...\n",
            "Epoch 32: train_loss = 0.4351, val_loss = 0.4253\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch 33: train_loss = 0.4308, val_loss = 0.4245\n",
            "Validation loss decreased (0.425334 --> 0.424079).  Saving model ...\n",
            "Epoch 34: train_loss = 0.4313, val_loss = 0.4241\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch 35: train_loss = 0.4306, val_loss = 0.4300\n",
            "EarlyStopping counter: 2 out of 5\n",
            "Epoch 36: train_loss = 0.4371, val_loss = 0.4301\n",
            "EarlyStopping counter: 3 out of 5\n",
            "Epoch 37: train_loss = 0.4350, val_loss = 0.4252\n",
            "EarlyStopping counter: 4 out of 5\n",
            "Epoch 38: train_loss = 0.4323, val_loss = 0.4247\n",
            "Validation loss decreased (0.424079 --> 0.422831).  Saving model ...\n",
            "Epoch 39: train_loss = 0.4304, val_loss = 0.4228\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch 40: train_loss = 0.4289, val_loss = 0.4233\n",
            "EarlyStopping counter: 2 out of 5\n",
            "Epoch 41: train_loss = 0.4276, val_loss = 0.4223\n",
            "Validation loss decreased (0.422831 --> 0.421471).  Saving model ...\n",
            "Epoch 42: train_loss = 0.4277, val_loss = 0.4215\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch 43: train_loss = 0.4265, val_loss = 0.4205\n",
            "EarlyStopping counter: 2 out of 5\n",
            "Epoch 44: train_loss = 0.4275, val_loss = 0.4258\n",
            "Validation loss decreased (0.421471 --> 0.420273).  Saving model ...\n",
            "Epoch 45: train_loss = 0.4283, val_loss = 0.4203\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Epoch 46: train_loss = 0.4249, val_loss = 0.4194\n",
            "EarlyStopping counter: 2 out of 5\n",
            "Epoch 47: train_loss = 0.4253, val_loss = 0.4233\n",
            "EarlyStopping counter: 3 out of 5\n",
            "Epoch 48: train_loss = 0.4294, val_loss = 0.4197\n",
            "EarlyStopping counter: 4 out of 5\n",
            "Epoch 49: train_loss = 0.4283, val_loss = 0.4212\n",
            "EarlyStopping counter: 5 out of 5\n",
            "Early stopping\n"
          ]
        }
      ],
      "source": [
        "# Assuming the model and dataset are already defined\n",
        "model = PhishHookNet(input_size=X_train.shape[1]).to(device)  # Adjust input size based on actual features\n",
        "\n",
        "# Loss function, optimizer, and early stopping\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=0.0001)\n",
        "early_stopping = EarlyStopping(verbose=True, delta=0.001)\n",
        "\n",
        "# Training loop with model saving based on validation loss improvement\n",
        "num_epochs = 50\n",
        "best_val_loss = float('inf')\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss = train(model, train_loader, optimizer, criterion)\n",
        "    val_loss, accuracy = validate(model, val_loader, criterion)\n",
        "    \n",
        "    # Early stopping\n",
        "    early_stopping(val_loss, model)\n",
        "    if early_stopping.early_stop:\n",
        "        print(\"Early stopping\")\n",
        "        break\n",
        "\n",
        "    print(f'Epoch {epoch+1}: train_loss = {train_loss:.4f}, val_loss = {val_loss:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training accuracy: 80.13%\n",
            "Validation accuracy: 80.08%\n",
            "Test accuracy: 80.32%\n"
          ]
        }
      ],
      "source": [
        "# Load the best model back\n",
        "model.load_state_dict(torch.load('phishing_url_model.pth'))\n",
        "\n",
        "# Evaluate the model on the test dataset\n",
        "model.eval()\n",
        "\n",
        "# Calculate accuracy\n",
        "train_accuracy = validate(model, train_loader, criterion)[1]\n",
        "val_accuracy = validate(model, val_loader, criterion)[1]\n",
        "test_accuracy = validate(model, test_loader, criterion)[1]\n",
        "\n",
        "# Print the results\n",
        "print(f'Training accuracy: {train_accuracy:.2f}%')\n",
        "print(f'Validation accuracy: {val_accuracy:.2f}%')\n",
        "print(f'Test accuracy: {test_accuracy:.2f}%')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
